{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d18f51b5becee20c",
   "metadata": {},
   "source": [
    "# Описательный анализ работы сервиса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd99e1173aee1330",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76c7d2633d5d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from os import path\n",
    "import sys\n",
    "sys.path.append(path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366b87bf9e3f3db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import jpeg4py as jpeg\n",
    "import cv2 \n",
    "\n",
    "from transforms import get_transforms\n",
    "from predict_utils import matrix_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb4be9d98cccba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_MODEL_PLATE_DET = '../../model_plate-det/experiments/exp-2/exp-2_plate-model.onnx'\n",
    "ONNX_MODEL_PLATE_OCR = '../../model_plate-ocr/experiments/exp1/exp-1_plate-ocr-model.onnx'\n",
    "TEST_IMAGE_PATH = '../../datasets/Car-plate-object-detection/train/img_1600.jpg'\n",
    "TEST_IMAGE_PATH_2 = '../../datasets/Car-plate-object-detection/train/img_1845.jpg'\n",
    "VOCAB = '#&0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZÄÅÖÜĆČĐŠŽАБВГДЕЖЗИКЛМНОПРСТУФХЦЧШЭЮЯ'\n",
    "\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d13ec6f0febdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onnx_preprocessing(\n",
    "    image,\n",
    "    image_size=(512, 512)\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert numpy-image to array for inference ONNX Runtime model.\n",
    "    \"\"\"\n",
    "\n",
    "    # resize\n",
    "    image = cv2.resize(image.copy(), image_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # normalize\n",
    "    mean = np.array((0.485, 0.456, 0.406), dtype=np.float32) * 255.0\n",
    "    std = np.array((0.229, 0.224, 0.225), dtype=np.float32) * 255.0\n",
    "    denominator = np.reciprocal(std, dtype=np.float32)\n",
    "    image = image.astype(np.float32)\n",
    "    image -= mean\n",
    "    image *= denominator\n",
    "\n",
    "    # transpose\n",
    "    image = image.transpose((2, 0, 1))[None]\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca2bfcf32521e1b",
   "metadata": {},
   "source": [
    "## Инициализируем сессии для моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e1be03ab32c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Доступные провайдеры, на которых можно выполнять вычисления\n",
    "print(ort.get_available_providers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f237c1e34ee28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем сессию\n",
    "\n",
    "# При инициализации сессии можно указать несколько провайдеров. Это может быть полезно, если хотим запускать код\n",
    "# на разных машинах. Например на машине с GPU у нас сработает CUDAExecutionProvider,\n",
    "# а на машине без GPU CPUExecutionProvider\n",
    "providers = [\n",
    "    'CUDAExecutionProvider',\n",
    "    'CPUExecutionProvider',\n",
    "]\n",
    "\n",
    "ort_session_det = ort.InferenceSession(\n",
    "    ONNX_MODEL_PLATE_DET,\n",
    "    providers=providers\n",
    ")\n",
    "\n",
    "ort_session_ocr = ort.InferenceSession(\n",
    "    ONNX_MODEL_PLATE_OCR,\n",
    "    providers=providers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa65a9a85cbd7599",
   "metadata": {},
   "source": [
    "## Используем 1ую модель - получаем кроп номера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8bcfbefb452004",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = jpeg.JPEG(TEST_IMAGE_PATH_2).decode()\n",
    "\n",
    "onnx_input = onnx_preprocessing(image, image_size=(512, 512))\n",
    "onnx_input = np.concatenate([onnx_input] * BATCH_SIZE)\n",
    "ort_inputs = {ort_session_det.get_inputs()[0].name: onnx_input}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b3764466b1108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выполняем инференс ONNX Runtime\n",
    "ort_outputs = ort_session_det.run(None, ort_inputs)[0]\n",
    "print(ort_outputs.shape)\n",
    "pr_mask = (ort_outputs.squeeze().round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f253503e825fd5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cv2.resize(image.copy(), (512,512), interpolation=cv2.INTER_LINEAR)\n",
    "image.shape\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47825511b139b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape[0] / a.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104cc597afe12978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output\n",
    "\n",
    "test_image = cv2.resize(image.copy(), (512,512), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "green_masks = np.zeros(test_image.shape, dtype=np.uint8)\n",
    "valid_area = np.argwhere(pr_mask > 0)\n",
    "green_masks[valid_area[:,0], valid_area[:,1], 1] = 255\n",
    "img_add = cv2.addWeighted(test_image, 0.7, green_masks, 0.3, 0)\n",
    "        \n",
    "plt.imshow(img_add, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472732b708beb1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cropping an image\n",
    "indexes = np.where(green_masks[:, :, 1] == 255)\n",
    "x_min = indexes[1].min()\n",
    "x_max = indexes[1].max()\n",
    "y_min = indexes[0].min()\n",
    "y_max = indexes[0].max()\n",
    "\n",
    "crop_image_smal = test_image[y_min:y_max, x_min:x_max, :]\n",
    "plt.imshow(crop_image_smal)\n",
    "\n",
    "# Convert to full-size image\n",
    "y_factor = image.shape[0] / test_image.shape[0]\n",
    "x_factor = image.shape[1] / test_image.shape[1]\n",
    "x_min_orig = int(x_min * x_factor)\n",
    "x_max_orig = int(x_max * x_factor)\n",
    "y_min_orig = int(y_min * y_factor)\n",
    "y_max_orig = int(y_max * y_factor)\n",
    "\n",
    "crop_image_orig = image[y_min_orig:y_max_orig, x_min_orig:x_max_orig, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ebe967409293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crop_image_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9d1cb0ef3d02fc",
   "metadata": {},
   "source": [
    "## Используем 2ую модель для OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628c85bafcd2426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = get_transforms(width=416, height=64, text_size=10, vocab=VOCAB, postprocessing=True, augmentations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6306f263e8f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_input_ocr = transforms(image=crop_image_orig, text='')['image'][None]\n",
    "onnx_input_ocr = np.concatenate([onnx_input_ocr] * BATCH_SIZE)\n",
    "print(onnx_input_ocr.shape)\n",
    "\n",
    "ort_inputs_ocr = {ort_session_ocr.get_inputs()[0].name: onnx_input_ocr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814aee088e3d3c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выполняем инференс ONNX Runtime\n",
    "ort_outputs_ocr = ort_session_ocr.run(None, ort_inputs_ocr)[0]\n",
    "print(ort_outputs_ocr.shape)\n",
    "\n",
    "string_pred, _ = matrix_to_string(torch.from_numpy(ort_outputs_ocr), VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f61ae0126e54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crop_image_orig)\n",
    "string_pred"
   ]
  },
  {
   "cell_type": "code",
   "id": "691083f9773a2952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
